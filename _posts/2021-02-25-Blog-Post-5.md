---
layout: post
title: Blog Post 5 Image Classification
---

In this blog post, we will try to use machine learning to identify pictures of dogs or cats. (Major parts of this Blog Post assignment, including several code chunks, are based on the TensorFlow Transfer Learning Tutorial.)

## §1. Load Packages and Obtain Data


```python
#importing packages 
import os
import tensorflow as tf
from tensorflow.keras import utils, layers, models 
import matplotlib.pyplot as plt
import numpy as np
```

Now let's try to access the data as follows：


```python
# location of data
_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'

# download the data and extract it
path_to_zip = utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)

# construct paths
PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')

train_dir = os.path.join(PATH, 'train')
validation_dir = os.path.join(PATH, 'validation')

# parameters for datasets
BATCH_SIZE = 32
IMG_SIZE = (160, 160)

# construct train and validation datasets 
train_dataset = utils.image_dataset_from_directory(train_dir,
                                             shuffle=True,
                                             batch_size=BATCH_SIZE,
                                             image_size=IMG_SIZE)

validation_dataset = utils.image_dataset_from_directory(validation_dir,
                                                  shuffle=True,
                                                  batch_size=BATCH_SIZE,
                                                  image_size=IMG_SIZE)

# construct the test dataset by taking every 5th observation out of the validation dataset
val_batches = tf.data.experimental.cardinality(validation_dataset)
test_dataset = validation_dataset.take(val_batches // 5)
validation_dataset = validation_dataset.skip(val_batches // 5)
```

    Downloading data from https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip
    68608000/68606236 [==============================] - 2s 0us/step
    68616192/68606236 [==============================] - 2s 0us/step
    Found 2000 files belonging to 2 classes.
    Found 1000 files belonging to 2 classes.


We can imagine that we have created TensorFlow Dataset s for training, validation, and testing. The dataset can be think of as a pipeline that feeds data to a model. Notice that we have used a keras utility called image_dataset_from_directory to construct a Dataset. 


```python
AUTOTUNE = tf.data.experimental.AUTOTUNE

train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)
validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)
test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)
```

To briefly explore or data set, we will write a function for visualization purposes. The first row will display three random pictures of cats, and the second row three random pictures of dogs:


```python
def two_row_visualization():
    plt.figure(figsize=(10, 10))
    # set labels
    class_names = ['cats', 'dogs']
      #organize images into two different lists
    for images, labels in train_dataset.take(1):
        cat_images = []
        dog_images = []
    while len(cat_images) <= 3 & len(dog_images) <=3:
        for i in range(32): #go through batch of 32 images
            if class_names[labels[i]] == 'dogs': #if label == dog, put in dog list
                  dog_images.append(images[i]) #if label == cat, put in cat list 
            else:
                  cat_images.append(images[i])
    fig,ax = plt.subplots(2, 3)
    for i in range(3):#plot the images in two seperate rows
      # print cat row 
      ax[0,i].imshow(cat_images[i].numpy().astype("uint8"))
      ax[0,i].axis('off')
      ax[0,i].set_title('Cat')
      # print dog row
      ax[1,i].set_title('Dog')
      ax[1,i].imshow(dog_images[i].numpy().astype("uint8"))
      ax[1,i].axis('off')
```


```python
two_row_visualization()
```


    <Figure size 720x720 with 0 Axes>



    
![output_9_1.png](/images/output_9_1.png)
    


To check label frequencies, we first create an iterator called labels_iterator. Note that cats have label 0 and dogs label 1. Then it will be easy to find out the number of images for dogs and cats.


```python
labels_iterator= train_dataset.unbatch().map(lambda image, label: label).as_numpy_iterator()
```


```python
sum(labels_iterator)
```




    1000



Thus we have 1000 images for dogs (so the rest 1000 are cats). Based on this information, we set the benchmark to be 50% accuracy. Our models should do much better than baseline in order to be considered making good progress.

## §2. First Model

The first model will make use of *tf.keras.Sequential*. Using the idea of convolution, we define a kernel matrix containing some numbers, and we “slide it over” the input data. At each location, we multiply the data values by the kernel matrix values, and add them together. The most common approach is to alternate Conv2D layers with MaxPooling2D layers. Pooling layers act as “summaries” that reduce the size of the data at each step. We then need to Flatten the data from 2d to 1d in order to pass it through the final Dense layers that creates the prediction.


```python
# Create our sequntial model similarly to in lecture 
model1 = models.Sequential([
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(160, 160, 3)),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(32, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(32, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Flatten(),
    layers.Dense(128, activation='relu'),
    layers.Dropout(0.2),
    layers.Dense(1)
])
```


```python
model1.summary()
```

    Model: "sequential"
    _________________________________________________________________
     Layer (type)                Output Shape              Param #   
    =================================================================
     conv2d (Conv2D)             (None, 158, 158, 32)      896       
                                                                     
     max_pooling2d (MaxPooling2D  (None, 79, 79, 32)       0         
     )                                                               
                                                                     
     conv2d_1 (Conv2D)           (None, 77, 77, 32)        9248      
                                                                     
     max_pooling2d_1 (MaxPooling  (None, 38, 38, 32)       0         
     2D)                                                             
                                                                     
     conv2d_2 (Conv2D)           (None, 36, 36, 32)        9248      
                                                                     
     max_pooling2d_2 (MaxPooling  (None, 18, 18, 32)       0         
     2D)                                                             
                                                                     
     flatten (Flatten)           (None, 10368)             0         
                                                                     
     dense (Dense)               (None, 128)               1327232   
                                                                     
     dropout (Dropout)           (None, 128)               0         
                                                                     
     dense_1 (Dense)             (None, 1)                 129       
                                                                     
    =================================================================
    Total params: 1,346,753
    Trainable params: 1,346,753
    Non-trainable params: 0
    _________________________________________________________________


To compile the model before training it, we use the Binary Cross Entropy function  with from_logits=True since the model provides a linear output.


```python
model1.compile(optimizer='adam',
              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),
              metrics=['accuracy'])
```


```python
history = model1.fit(train_dataset, 
                     epochs=20, 
                     validation_data=validation_dataset)
```

    Epoch 1/20
    63/63 [==============================] - 16s 82ms/step - loss: 4.7916 - accuracy: 0.5105 - val_loss: 0.6809 - val_accuracy: 0.5099
    Epoch 2/20
    63/63 [==============================] - 5s 74ms/step - loss: 0.6676 - accuracy: 0.5825 - val_loss: 0.6707 - val_accuracy: 0.5730
    Epoch 3/20
    63/63 [==============================] - 5s 75ms/step - loss: 0.5920 - accuracy: 0.6695 - val_loss: 0.6912 - val_accuracy: 0.5260
    Epoch 4/20
    63/63 [==============================] - 5s 74ms/step - loss: 0.4609 - accuracy: 0.7490 - val_loss: 0.7594 - val_accuracy: 0.6151
    Epoch 5/20
    63/63 [==============================] - 5s 76ms/step - loss: 0.4065 - accuracy: 0.8095 - val_loss: 0.7876 - val_accuracy: 0.5730
    Epoch 6/20
    63/63 [==============================] - 5s 74ms/step - loss: 0.3072 - accuracy: 0.8570 - val_loss: 0.9649 - val_accuracy: 0.5990
    Epoch 7/20
    63/63 [==============================] - 5s 75ms/step - loss: 0.1744 - accuracy: 0.9285 - val_loss: 1.2030 - val_accuracy: 0.6213
    Epoch 8/20
    63/63 [==============================] - 5s 75ms/step - loss: 0.1100 - accuracy: 0.9660 - val_loss: 1.2886 - val_accuracy: 0.6052
    Epoch 9/20
    63/63 [==============================] - 5s 74ms/step - loss: 0.0709 - accuracy: 0.9785 - val_loss: 1.4181 - val_accuracy: 0.6002
    Epoch 10/20
    63/63 [==============================] - 6s 99ms/step - loss: 0.0508 - accuracy: 0.9825 - val_loss: 1.6584 - val_accuracy: 0.6200
    Epoch 11/20
    63/63 [==============================] - 5s 77ms/step - loss: 0.0400 - accuracy: 0.9895 - val_loss: 1.9555 - val_accuracy: 0.6052
    Epoch 12/20
    63/63 [==============================] - 5s 78ms/step - loss: 0.0671 - accuracy: 0.9775 - val_loss: 1.7353 - val_accuracy: 0.6200
    Epoch 13/20
    63/63 [==============================] - 5s 76ms/step - loss: 0.0558 - accuracy: 0.9800 - val_loss: 1.4565 - val_accuracy: 0.6176
    Epoch 14/20
    63/63 [==============================] - 5s 81ms/step - loss: 0.0406 - accuracy: 0.9825 - val_loss: 1.9405 - val_accuracy: 0.6139
    Epoch 15/20
    63/63 [==============================] - 5s 79ms/step - loss: 0.0344 - accuracy: 0.9875 - val_loss: 1.9205 - val_accuracy: 0.5903
    Epoch 16/20
    63/63 [==============================] - 5s 80ms/step - loss: 0.0285 - accuracy: 0.9915 - val_loss: 1.7779 - val_accuracy: 0.6151
    Epoch 17/20
    63/63 [==============================] - 5s 78ms/step - loss: 0.0165 - accuracy: 0.9955 - val_loss: 1.6955 - val_accuracy: 0.6287
    Epoch 18/20
    63/63 [==============================] - 5s 81ms/step - loss: 0.0137 - accuracy: 0.9970 - val_loss: 2.3730 - val_accuracy: 0.6064
    Epoch 19/20
    63/63 [==============================] - 5s 79ms/step - loss: 0.0040 - accuracy: 0.9990 - val_loss: 2.2772 - val_accuracy: 0.6077
    Epoch 20/20
    63/63 [==============================] - 5s 79ms/step - loss: 0.0088 - accuracy: 0.9970 - val_loss: 2.4309 - val_accuracy: 0.6040


To visualize history:


```python
def visualize_history(history, min_acc):
    acc = history.history['accuracy']
    val_acc = history.history['val_accuracy']

    loss = history.history['loss']
    val_loss = history.history['val_loss']

    plt.figure(figsize=(8, 8))
    plt.subplot(2, 1, 1)
    plt.plot(acc, label='Training Accuracy')
    plt.plot(val_acc, label='Validation Accuracy')
    plt.axhline(y= min_acc, color='black', label='Minimum accuracy = {m}%'.format(m=round(min_acc*100, 1)))
    plt.axhline(y=0.50, color='green', label='Baseline accuracy = 50%')
    plt.legend(loc='lower right')
    plt.ylabel('Accuracy')
    plt.ylim([min(plt.ylim()),1])
    plt.title('Training and Validation Accuracy')

    plt.subplot(2, 1, 2)
    plt.plot(loss, label='Training Loss')
    plt.plot(val_loss, label='Validation Loss')
    plt.legend(loc='upper right')
    plt.ylabel('Cross Entropy')
    plt.ylim([0,1.0])
    plt.title('Training and Validation Loss')
    plt.xlabel('epoch')
    plt.show()
```


```python
visualize_history(history, 0.52)
```


    
![output_23_0.png](/images/output_23_0.png)
    


The accuracy of my model stabilized around **60%** as we can see from the yellow line. Compared with the baseline accuracy of 50%, it has improved approximately 10%. However, we do observe clear overfitting as the accuracy on training data is much higher than the validation accuracy.

## §3. Model with Data Augmentation

For our second model, we would like to add data augmentation into the model. Data augmentation refers to the practice of including modified copies of the same image in the training set. In the following steps, we would want to make sure that the model still recognizes cats/dogs after the picture are flipped/rotated.

Seems like the two augmentation layers are working well. Now we build our second model in which we use the two augmentation layers.


```python
random_flip = tf.keras.Sequential([
    # including the RandomFlip layer
    layers.RandomFlip('horizontal_and_vertical'),
])
```


```python
for images, labels in train_dataset.take(1):
    fig,ax = plt.subplots(1,4, figsize = (20,20)) #create plot
    image1 = images[0]
    ax[0].imshow(image1.numpy().astype("uint8")) #plot original image
    ax[0].set_title('Original')
    ax[0].axis('off')
    for i in range(3):
        test = random_flip(tf.expand_dims(image1, 0),training=True) #plot random flipped image
        ax[i+1].imshow(test[0]/225)
        ax[i+1].axis('off')
        ax[i+1].set_title('Random Flip '+str(i+1))
```

    Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
    Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
    Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).



    
![output_29_1.png](/images/output_29_1.png)
    



```python
random_rotation = tf.keras.Sequential([
    layers.RandomRotation(factor=0.2, fill_mode='reflect', interpolation='bilinear',
    seed=None) 
])
```


```python
for images, labels in train_dataset.take(1):
    fig,ax = plt.subplots(1,4, figsize = (20,20)) #create plot
    ax[0].imshow(images[0].numpy().astype("uint8")) #plot original image
    ax[0].set_title('Original')
    ax[0].axis('off')
    for i in range(3):
        test = random_rotation(tf.expand_dims(images[0], 0),training=True) #plot random flipped image
        ax[i+1].imshow(test[0]/225)
        ax[i+1].axis('off')
        ax[i+1].set_title('Random Rotation '+str(i+1))
```

    Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
    Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).
    Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).



    
![output_31_1.png](/images/output_31_1.png)
    



```python
# Create our sequntial model similarly to in lecture 
model2 = models.Sequential([
    layers.experimental.preprocessing.RandomFlip('horizontal_and_vertical'),
    layers.experimental.preprocessing.RandomRotation(0.25),
    
    layers.Conv2D(32, (10, 5), activation='relu', input_shape=(160, 160, 3)),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(32, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
 
    layers.Flatten(),
    layers.Dense(128, activation='relu'),
    layers.Dropout(0.2),
    layers.Dense(1)
])
```


```python
model2.compile(optimizer='adam',
              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),
              metrics=['accuracy'])
```


```python
history1 = model2.fit(train_dataset, 
                     epochs=20, 
                      validation_data=validation_dataset)
```

    Epoch 1/20
    63/63 [==============================] - 6s 93ms/step - loss: 0.6405 - accuracy: 0.5980 - val_loss: 0.6012 - val_accuracy: 0.6460
    Epoch 2/20
    63/63 [==============================] - 6s 84ms/step - loss: 0.6169 - accuracy: 0.6230 - val_loss: 0.6005 - val_accuracy: 0.6324
    Epoch 3/20
    63/63 [==============================] - 6s 84ms/step - loss: 0.6483 - accuracy: 0.5920 - val_loss: 0.6294 - val_accuracy: 0.5990
    Epoch 4/20
    63/63 [==============================] - 6s 84ms/step - loss: 0.6280 - accuracy: 0.6100 - val_loss: 0.6515 - val_accuracy: 0.5210
    Epoch 5/20
    63/63 [==============================] - 7s 99ms/step - loss: 0.6493 - accuracy: 0.5685 - val_loss: 0.6179 - val_accuracy: 0.5953
    Epoch 6/20
    63/63 [==============================] - 6s 83ms/step - loss: 0.6319 - accuracy: 0.6110 - val_loss: 0.6616 - val_accuracy: 0.5718
    Epoch 7/20
    63/63 [==============================] - 6s 90ms/step - loss: 0.6272 - accuracy: 0.6225 - val_loss: 0.6199 - val_accuracy: 0.5941
    Epoch 8/20
    63/63 [==============================] - 6s 86ms/step - loss: 0.6191 - accuracy: 0.6355 - val_loss: 0.6173 - val_accuracy: 0.6584
    Epoch 9/20
    63/63 [==============================] - 6s 84ms/step - loss: 0.6504 - accuracy: 0.5920 - val_loss: 0.6240 - val_accuracy: 0.6163
    Epoch 10/20
    63/63 [==============================] - 6s 83ms/step - loss: 0.6406 - accuracy: 0.6020 - val_loss: 0.6056 - val_accuracy: 0.6646
    Epoch 11/20
    63/63 [==============================] - 5s 82ms/step - loss: 0.6318 - accuracy: 0.5965 - val_loss: 0.5966 - val_accuracy: 0.6510
    Epoch 12/20
    63/63 [==============================] - 6s 83ms/step - loss: 0.6214 - accuracy: 0.6305 - val_loss: 0.6037 - val_accuracy: 0.6300
    Epoch 13/20
    63/63 [==============================] - 6s 83ms/step - loss: 0.6237 - accuracy: 0.6160 - val_loss: 0.6343 - val_accuracy: 0.5631
    Epoch 14/20
    63/63 [==============================] - 5s 82ms/step - loss: 0.6285 - accuracy: 0.6185 - val_loss: 0.5757 - val_accuracy: 0.6634
    Epoch 15/20
    63/63 [==============================] - 6s 85ms/step - loss: 0.6093 - accuracy: 0.6315 - val_loss: 0.5717 - val_accuracy: 0.6609
    Epoch 16/20
    63/63 [==============================] - 6s 83ms/step - loss: 0.6148 - accuracy: 0.6305 - val_loss: 0.6038 - val_accuracy: 0.6584
    Epoch 17/20
    63/63 [==============================] - 6s 84ms/step - loss: 0.6177 - accuracy: 0.6295 - val_loss: 0.6029 - val_accuracy: 0.6559
    Epoch 18/20
    63/63 [==============================] - 6s 84ms/step - loss: 0.6064 - accuracy: 0.6400 - val_loss: 0.6212 - val_accuracy: 0.6176
    Epoch 19/20
    63/63 [==============================] - 6s 85ms/step - loss: 0.6149 - accuracy: 0.6495 - val_loss: 0.6271 - val_accuracy: 0.5817
    Epoch 20/20
    63/63 [==============================] - 6s 84ms/step - loss: 0.6070 - accuracy: 0.6350 - val_loss: 0.5797 - val_accuracy: 0.6609



```python
visualize_history(history1, 0.55)
```


    
![output_35_0.png](/images/output_35_0.png)
    


The accuracy of our second model stabilized **between 60% and 65%** during training. The model has achieved around 2 to 5 percent higher accuracy, but not much. Since the training accuracy is close to the validation accuracy we did not observe overfitting for our second model.

## §4. Data Preprocessing

In real life, it is a good practice to normalize RGB values between 0 to 1 or -1 to 1 for the model to train faster. By normalizing our RGB values in this way, we could minimize training energy need to have the weights adjust to the data scale and maximize training energy needed for handling the actual signal in the data.


```python
#process input images
i = tf.keras.Input(shape=(160, 160, 3))
x = tf.keras.applications.mobilenet_v2.preprocess_input(i)
preprocessor = tf.keras.Model(inputs = [i], outputs = [x])
```

We want to incorporate the preprocessor layer before the augmentation layer. Then we fit our model3.


```python
# Create our sequntial model similarly to in lecture 
model3 = models.Sequential([
    # Preprocessor
    preprocessor,
    
    layers.experimental.preprocessing.RandomFlip('horizontal_and_vertical'),
    layers.experimental.preprocessing.RandomRotation(0.2),
    
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(160, 160, 3)),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(32, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(32, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Flatten(),
    layers.Dense(256, activation='relu'),
    layers.Dropout(0.2),
    layers.Dense(1)
])
```


```python
model3.compile(optimizer='adam',
              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),
              metrics=['accuracy'])
```


```python
model3.summary()
```

    Model: "sequential_4"
    _________________________________________________________________
     Layer (type)                Output Shape              Param #   
    =================================================================
     model (Functional)          (None, 160, 160, 3)       0         
                                                                     
     random_flip_2 (RandomFlip)  (None, 160, 160, 3)       0         
                                                                     
     random_rotation_2 (RandomRo  (None, 160, 160, 3)      0         
     tation)                                                         
                                                                     
     conv2d_6 (Conv2D)           (None, 158, 158, 32)      896       
                                                                     
     max_pooling2d_6 (MaxPooling  (None, 79, 79, 32)       0         
     2D)                                                             
                                                                     
     conv2d_7 (Conv2D)           (None, 77, 77, 32)        9248      
                                                                     
     max_pooling2d_7 (MaxPooling  (None, 38, 38, 32)       0         
     2D)                                                             
                                                                     
     conv2d_8 (Conv2D)           (None, 36, 36, 32)        9248      
                                                                     
     max_pooling2d_8 (MaxPooling  (None, 18, 18, 32)       0         
     2D)                                                             
                                                                     
     flatten_2 (Flatten)         (None, 10368)             0         
                                                                     
     dense_4 (Dense)             (None, 256)               2654464   
                                                                     
     dropout_2 (Dropout)         (None, 256)               0         
                                                                     
     dense_5 (Dense)             (None, 1)                 257       
                                                                     
    =================================================================
    Total params: 2,674,113
    Trainable params: 2,674,113
    Non-trainable params: 0
    _________________________________________________________________



```python
history2 = model3.fit(train_dataset, 
                     epochs=20, 
                     validation_data=validation_dataset)
```

    Epoch 1/20
    63/63 [==============================] - 7s 81ms/step - loss: 0.7013 - accuracy: 0.5050 - val_loss: 0.6784 - val_accuracy: 0.4975
    Epoch 2/20
    63/63 [==============================] - 5s 77ms/step - loss: 0.6607 - accuracy: 0.5665 - val_loss: 0.6364 - val_accuracy: 0.6436
    Epoch 3/20
    63/63 [==============================] - 5s 78ms/step - loss: 0.6538 - accuracy: 0.5830 - val_loss: 0.6137 - val_accuracy: 0.5916
    Epoch 4/20
    63/63 [==============================] - 5s 77ms/step - loss: 0.6098 - accuracy: 0.6390 - val_loss: 0.6060 - val_accuracy: 0.6287
    Epoch 5/20
    63/63 [==============================] - 6s 83ms/step - loss: 0.6005 - accuracy: 0.6495 - val_loss: 0.5938 - val_accuracy: 0.6770
    Epoch 6/20
    63/63 [==============================] - 7s 105ms/step - loss: 0.5941 - accuracy: 0.6535 - val_loss: 0.5906 - val_accuracy: 0.6646
    Epoch 7/20
    63/63 [==============================] - 7s 100ms/step - loss: 0.5827 - accuracy: 0.6655 - val_loss: 0.5909 - val_accuracy: 0.6832
    Epoch 8/20
    63/63 [==============================] - 6s 91ms/step - loss: 0.5865 - accuracy: 0.6600 - val_loss: 0.5856 - val_accuracy: 0.6547
    Epoch 9/20
    63/63 [==============================] - 6s 94ms/step - loss: 0.5547 - accuracy: 0.6810 - val_loss: 0.5956 - val_accuracy: 0.7079
    Epoch 10/20
    63/63 [==============================] - 6s 80ms/step - loss: 0.5551 - accuracy: 0.6935 - val_loss: 0.5666 - val_accuracy: 0.6844
    Epoch 11/20
    63/63 [==============================] - 6s 92ms/step - loss: 0.5560 - accuracy: 0.6895 - val_loss: 0.5308 - val_accuracy: 0.6931
    Epoch 12/20
    63/63 [==============================] - 7s 109ms/step - loss: 0.5435 - accuracy: 0.7090 - val_loss: 0.5370 - val_accuracy: 0.6943
    Epoch 13/20
    63/63 [==============================] - 5s 79ms/step - loss: 0.5412 - accuracy: 0.7025 - val_loss: 0.5409 - val_accuracy: 0.7153
    Epoch 14/20
    63/63 [==============================] - 6s 88ms/step - loss: 0.5330 - accuracy: 0.7030 - val_loss: 0.5677 - val_accuracy: 0.7302
    Epoch 15/20
    63/63 [==============================] - 6s 84ms/step - loss: 0.5194 - accuracy: 0.7285 - val_loss: 0.5411 - val_accuracy: 0.7203
    Epoch 16/20
    63/63 [==============================] - 5s 79ms/step - loss: 0.5271 - accuracy: 0.7305 - val_loss: 0.5515 - val_accuracy: 0.6894
    Epoch 17/20
    63/63 [==============================] - 5s 79ms/step - loss: 0.5293 - accuracy: 0.7085 - val_loss: 0.5694 - val_accuracy: 0.7178
    Epoch 18/20
    63/63 [==============================] - 5s 82ms/step - loss: 0.5222 - accuracy: 0.7305 - val_loss: 0.5069 - val_accuracy: 0.7166
    Epoch 19/20
    63/63 [==============================] - 5s 81ms/step - loss: 0.5208 - accuracy: 0.7240 - val_loss: 0.5314 - val_accuracy: 0.7265
    Epoch 20/20
    63/63 [==============================] - 5s 82ms/step - loss: 0.5021 - accuracy: 0.7340 - val_loss: 0.5174 - val_accuracy: 0.7401



```python
visualize_history(history2, 0.7)
```


    
![output_45_0.png](/images/output_45_0.png)
    


The accuracy of our thrid model stabilized around **70%** as required. Compared with model1, it achieves about 5-15% higher accuracy. Model3 is doing much better than model1. Since the training accuracy is very close to the validation accuracy we did not observe overfitting in model3 unlike in model1.

## §5. Transfer Learning

In the previous steps we have been training models for distinguishing between cats and dogs from scratch. In real situations, there can be existing model that does a related task/ We are going to first access a pre-existing “base model”, incorporate it into a full model for our current task, and then train that model. This is called transfer learning.


```python
IMG_SHAPE = IMG_SIZE + (3,)
base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,
                                               include_top=False,
                                               weights='imagenet')
base_model.trainable = False

i = tf.keras.Input(shape=IMG_SHAPE)
x = base_model(i, training = False)
base_model_layer = tf.keras.Model(inputs = [i], outputs = [x])
```

    Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_160_no_top.h5
    9412608/9406464 [==============================] - 0s 0us/step
    9420800/9406464 [==============================] - 0s 0us/step



```python
#build our 4th model
model4 = tf.keras.Sequential([
    # Preprocessor
    preprocessor,
    # Data Augmentation
    layers.RandomFlip("horizontal_and_vertical"),
    layers.RandomRotation(0.25),

    # Base model 
    base_model_layer,
    layers.GlobalMaxPooling2D(),
    layers.Dropout(0.2),
    layers.Dense(1)
])
```

Similar as before, we compile the model and run:


```python
model4.compile(optimizer='adam',
              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),
              metrics=['accuracy'])
```


```python
model4.summary()
```

    Model: "sequential_6"
    _________________________________________________________________
     Layer (type)                Output Shape              Param #   
    =================================================================
     model_1 (Functional)        (None, 160, 160, 3)       0         
                                                                     
     random_flip_4 (RandomFlip)  (None, 160, 160, 3)       0         
                                                                     
     random_rotation_4 (RandomRo  (None, 160, 160, 3)      0         
     tation)                                                         
                                                                     
     model_2 (Functional)        (None, 5, 5, 1280)        2257984   
                                                                     
     global_max_pooling2d (Globa  (None, 1280)             0         
     lMaxPooling2D)                                                  
                                                                     
     dropout_4 (Dropout)         (None, 1280)              0         
                                                                     
     dense_8 (Dense)             (None, 1)                 1281      
                                                                     
    =================================================================
    Total params: 2,259,265
    Trainable params: 1,281
    Non-trainable params: 2,257,984
    _________________________________________________________________



```python
history3 = model4.fit(train_dataset, 
                     epochs=20, 
                     validation_data=validation_dataset)
```

    Epoch 1/20
    63/63 [==============================] - 11s 112ms/step - loss: 0.8480 - accuracy: 0.7360 - val_loss: 0.1659 - val_accuracy: 0.9245
    Epoch 2/20
    63/63 [==============================] - 6s 88ms/step - loss: 0.4655 - accuracy: 0.8410 - val_loss: 0.1041 - val_accuracy: 0.9604
    Epoch 3/20
    63/63 [==============================] - 6s 88ms/step - loss: 0.3871 - accuracy: 0.8670 - val_loss: 0.0855 - val_accuracy: 0.9629
    Epoch 4/20
    63/63 [==============================] - 6s 87ms/step - loss: 0.3958 - accuracy: 0.8650 - val_loss: 0.0839 - val_accuracy: 0.9629
    Epoch 5/20
    63/63 [==============================] - 6s 88ms/step - loss: 0.3349 - accuracy: 0.8850 - val_loss: 0.0874 - val_accuracy: 0.9629
    Epoch 6/20
    63/63 [==============================] - 6s 87ms/step - loss: 0.3146 - accuracy: 0.8855 - val_loss: 0.0754 - val_accuracy: 0.9653
    Epoch 7/20
    63/63 [==============================] - 6s 87ms/step - loss: 0.3034 - accuracy: 0.8990 - val_loss: 0.0902 - val_accuracy: 0.9604
    Epoch 8/20
    63/63 [==============================] - 6s 87ms/step - loss: 0.2906 - accuracy: 0.8945 - val_loss: 0.0719 - val_accuracy: 0.9641
    Epoch 9/20
    63/63 [==============================] - 6s 87ms/step - loss: 0.2840 - accuracy: 0.9015 - val_loss: 0.0661 - val_accuracy: 0.9666
    Epoch 10/20
    63/63 [==============================] - 6s 88ms/step - loss: 0.2705 - accuracy: 0.8995 - val_loss: 0.0627 - val_accuracy: 0.9691
    Epoch 11/20
    63/63 [==============================] - 6s 87ms/step - loss: 0.2728 - accuracy: 0.9050 - val_loss: 0.0685 - val_accuracy: 0.9666
    Epoch 12/20
    63/63 [==============================] - 6s 87ms/step - loss: 0.2442 - accuracy: 0.9110 - val_loss: 0.0744 - val_accuracy: 0.9616
    Epoch 13/20
    63/63 [==============================] - 6s 88ms/step - loss: 0.2649 - accuracy: 0.9035 - val_loss: 0.0732 - val_accuracy: 0.9691
    Epoch 14/20
    63/63 [==============================] - 6s 89ms/step - loss: 0.2488 - accuracy: 0.9065 - val_loss: 0.0712 - val_accuracy: 0.9703
    Epoch 15/20
    63/63 [==============================] - 6s 88ms/step - loss: 0.2339 - accuracy: 0.9070 - val_loss: 0.0814 - val_accuracy: 0.9678
    Epoch 16/20
    63/63 [==============================] - 6s 88ms/step - loss: 0.2492 - accuracy: 0.9090 - val_loss: 0.0666 - val_accuracy: 0.9678
    Epoch 17/20
    63/63 [==============================] - 6s 87ms/step - loss: 0.2236 - accuracy: 0.9140 - val_loss: 0.0638 - val_accuracy: 0.9728
    Epoch 18/20
    63/63 [==============================] - 6s 88ms/step - loss: 0.2241 - accuracy: 0.9120 - val_loss: 0.0699 - val_accuracy: 0.9703
    Epoch 19/20
    63/63 [==============================] - 6s 86ms/step - loss: 0.2127 - accuracy: 0.9145 - val_loss: 0.0658 - val_accuracy: 0.9715
    Epoch 20/20
    63/63 [==============================] - 6s 87ms/step - loss: 0.2284 - accuracy: 0.9125 - val_loss: 0.0696 - val_accuracy: 0.9666



```python
visualize_history(history3, 0.95)
```


    
![output_55_0.png](/images/output_55_0.png)
    


We are happy to see that the model accuracy stabilized above **95%**! Compared with model3, it has about 20-25% better accuracy. Model4 is doing much better than all previous models. Since the training accuracy is close to the validation accuracy, again we did not observe overfitting in model4.



## §6. Score on Test Data

Before ending our blog post, we evaluate the accuracy of our best model on the test data.


```python
model4.evaluate(test_dataset)
```

    6/6 [==============================] - 1s 55ms/step - loss: 0.0983 - accuracy: 0.9583





    [0.09826063364744186, 0.9583333134651184]



Nice job! We have achieved **95%** accuracy on unseen data. This is a very high score. From this we can see how helpful and efficient transfer learning is in many cases. This is the end of our blog post 5.


```python

```
