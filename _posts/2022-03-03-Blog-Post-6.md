---
layout: post
title: Blog Post 6 Fake News Classifier
---

In this last blog post, we are going to build our own models that identifies whether a piece of news is fake. We will try to build three different models using *Functional API* and compare their results.

As usual, we start by importing the necessary packages:


```python
import pandas as pd
from nltk.corpus import stopwords
import tensorflow as tf
import re
import string
import nltk
nltk.download('stopwords')
from tensorflow.keras import layers 
from tensorflow.keras import losses 
from tensorflow import keras
import plotly.express as px
import plotly.io as pio 
pio.templates.default = "plotly_white"
from tensorflow.keras.layers.experimental.preprocessing import TextVectorization 
from tensorflow.keras.layers.experimental.preprocessing import StringLookup
```

    [nltk_data] Downloading package stopwords to /root/nltk_data...
    [nltk_data]   Unzipping corpora/stopwords.zip.


## §1. Acquire Training Data

The training data comes from Kaggle. We extract it from url.


```python
train_url = "https://github.com/PhilChodrow/PIC16b/blob/master/datasets/fake_news_train.csv?raw=true"
```


```python
traindata = pd.read_csv(train_url)
traindata.head()
```





  <div id="df-aa6c2cad-b667-4950-b294-1f082781055c">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Unnamed: 0</th>
      <th>title</th>
      <th>text</th>
      <th>fake</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>17366</td>
      <td>Merkel: Strong result for Austria's FPO 'big c...</td>
      <td>German Chancellor Angela Merkel said on Monday...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>5634</td>
      <td>Trump says Pence will lead voter fraud panel</td>
      <td>WEST PALM BEACH, Fla.President Donald Trump sa...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>17487</td>
      <td>JUST IN: SUSPECTED LEAKER and “Close Confidant...</td>
      <td>On December 5, 2017, Circa s Sara Carter warne...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>12217</td>
      <td>Thyssenkrupp has offered help to Argentina ove...</td>
      <td>Germany s Thyssenkrupp, has offered assistance...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5535</td>
      <td>Trump say appeals court decision on travel ban...</td>
      <td>President Donald Trump on Thursday called the ...</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-aa6c2cad-b667-4950-b294-1f082781055c')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-aa6c2cad-b667-4950-b294-1f082781055c button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-aa6c2cad-b667-4950-b294-1f082781055c');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>




We can see that the data includes three useful columns: title, text, and the target variable fake (1 means it is a fake news, 0 otherwise).

## §2. Make a Dataset

We want to write a function that helps us make a tensorflow dataset. In particular, the function should be able to
1. remove all stopwords
2. return a tensorflow dataset with two inputs and one output. The input should be of the form (title, text) , and the output should consist only of the fake column. 
We also want to batch the data to increase training accuracy later.


```python
def make_dataset(df):
  """
  This function helps to remove stopwords in data and returns a tf dataset.
  """
  stop = stopwords.words('english')
  #remove stopwords from titles and texts
  df['title'] = df['title'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))
  df['text'] = df['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))
  
  #create the tf dataset as required
  data = tf.data.Dataset.from_tensor_slices(
      (
          {
              "title" : df[["title"]],
              "text" : df[["text"]]
          },{
              "fake" : df[["fake"]]
          }
      )
  )

  #return a batched dataset
  return data.batch(100)
```


```python
#make our data
data = make_dataset(traindata)
```

Now that we have the tf dataset (this is only our training data), we take out **20% as validation data**. Testing data will be provided later.


```python
data = data.shuffle(buffer_size = len(data))
#20% as validation
val_size   = int(0.2*len(data))
val    = data.take(val_size)
train  = data.skip(val_size)
```

We would also want to examine the **base rate**, the accuracy of a model that always makes the same guess (for example, such a model might always say “fake news!”). Note that for around **52.3%** of time this guess will be correct. Our models must achieve a significantly higher accuracy in order to be helpful.


```python
traindata.groupby("fake").size()
```




    fake
    0    10709
    1    11740
    dtype: int64




```python
#calculate the base rate
11740/(11740+10709)
```




    0.522963160942581



## §3. Create Models

Before building our model, we would like to set a goal for today's blog post. We want to examine the following question:

*When detecting fake news, is it most effective to focus on only the title of the article, the full text of the article, or both?*

The first model we build will use only the title variable, the second will use only text, and the third both.


```python
#set up the inputs
#note tha both inputs have the same type and shape

title_input = keras.Input(
    shape = (1,),
    name = "title",
    dtype = "string"
)
text_input = keras.Input(
    shape = (1,),
    name = "text",
    dtype = "string"
)
```

Specifically, we create the embedding layer outside of all models so that we can reuse this layer for each model we build. I specified the vocab size to be a bit larger than the example in lecture because I want to make it easier to interpret the embedding result later on.


```python
size_vocabulary = 3000
vectorize_layer = TextVectorization(output_mode='int',max_tokens=3000)
vectorize_layer.adapt(train.map(lambda x, y: x["title"]))
vectorize_layer.adapt(train.map(lambda x, y: x["text"]))
#embedding layer
embedding = layers.Embedding(size_vocabulary, 3, name = "embedding") 
```

## First Model

For the first model, we will only be using the article **title**. I have tried several different parameters for the Dropout layer. A dropout rate of 10% is ideal from my observation, because higher dropout resulted in a perceivably higher accuracy for the validation set than the training set, which is somewhat unnecessary. Also the overall accuracy is negatively affected. When I used 10% dropout rate, the validation and training accuracy were similar, and they both reached a very high overall accuracy.

I also tried ou 20/30/40 epochs. Over several trials, the model performance became stable for more than 30 epochs.


```python
title_features = vectorize_layer(title_input)
title_features = embedding(title_features) 
#include two drop out layers to prevent overfitting
title_features = layers.Dropout(0.1)(title_features)
title_features = layers.GlobalAveragePooling1D()(title_features)
title_features = layers.Dropout(0.1)(title_features)
title_features = layers.Dense(32, activation='relu')(title_features)
```


```python
output = layers.Dense(2, name = "fake")(title_features)
```


```python
model = keras.Model(
      inputs = title_input,
      outputs = output
        )
```


```python
#compile the model
model.compile(optimizer = "adam",
loss = losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy']
)
```

Now we train the model using 40 epochs.


```python
history = model.fit(train, validation_data=val, epochs = 40)
```

    Epoch 1/40


    /usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:559: UserWarning: Input dict contained keys ['text'] which did not match any model input. They will be ignored by the model.
      inputs = self._flatten_to_reference_inputs(inputs)


    180/180 [==============================] - 5s 9ms/step - loss: 0.5918 - accuracy: 0.7755 - val_loss: 0.3982 - val_accuracy: 0.9196
    Epoch 2/40
    180/180 [==============================] - 2s 8ms/step - loss: 0.2735 - accuracy: 0.9191 - val_loss: 0.1806 - val_accuracy: 0.9498
    Epoch 3/40
    180/180 [==============================] - 1s 8ms/step - loss: 0.1615 - accuracy: 0.9468 - val_loss: 0.1158 - val_accuracy: 0.9664
    Epoch 4/40
    180/180 [==============================] - 1s 8ms/step - loss: 0.1194 - accuracy: 0.9615 - val_loss: 0.0951 - val_accuracy: 0.9684
    Epoch 5/40
    180/180 [==============================] - 1s 8ms/step - loss: 0.0925 - accuracy: 0.9705 - val_loss: 0.0790 - val_accuracy: 0.9722
    Epoch 6/40
    180/180 [==============================] - 2s 8ms/step - loss: 0.0708 - accuracy: 0.9774 - val_loss: 0.0595 - val_accuracy: 0.9804
    Epoch 7/40
    180/180 [==============================] - 2s 8ms/step - loss: 0.0643 - accuracy: 0.9807 - val_loss: 0.0549 - val_accuracy: 0.9827
    Epoch 8/40
    180/180 [==============================] - 1s 8ms/step - loss: 0.0546 - accuracy: 0.9832 - val_loss: 0.0456 - val_accuracy: 0.9842
    Epoch 9/40
    180/180 [==============================] - 2s 8ms/step - loss: 0.0491 - accuracy: 0.9850 - val_loss: 0.0432 - val_accuracy: 0.9858
    Epoch 10/40
    180/180 [==============================] - 1s 8ms/step - loss: 0.0452 - accuracy: 0.9861 - val_loss: 0.0326 - val_accuracy: 0.9898
    Epoch 11/40
    180/180 [==============================] - 1s 8ms/step - loss: 0.0411 - accuracy: 0.9873 - val_loss: 0.0375 - val_accuracy: 0.9871
    Epoch 12/40
    180/180 [==============================] - 1s 8ms/step - loss: 0.0386 - accuracy: 0.9881 - val_loss: 0.0294 - val_accuracy: 0.9913
    Epoch 13/40
    180/180 [==============================] - 1s 8ms/step - loss: 0.0360 - accuracy: 0.9879 - val_loss: 0.0282 - val_accuracy: 0.9908
    Epoch 14/40
    180/180 [==============================] - 1s 8ms/step - loss: 0.0353 - accuracy: 0.9882 - val_loss: 0.0242 - val_accuracy: 0.9916
    Epoch 15/40
    180/180 [==============================] - 2s 8ms/step - loss: 0.0320 - accuracy: 0.9903 - val_loss: 0.0227 - val_accuracy: 0.9944
    Epoch 16/40
    180/180 [==============================] - 1s 8ms/step - loss: 0.0317 - accuracy: 0.9899 - val_loss: 0.0225 - val_accuracy: 0.9926
    Epoch 17/40
    180/180 [==============================] - 1s 8ms/step - loss: 0.0304 - accuracy: 0.9901 - val_loss: 0.0207 - val_accuracy: 0.9948
    Epoch 18/40
    180/180 [==============================] - 2s 8ms/step - loss: 0.0298 - accuracy: 0.9899 - val_loss: 0.0264 - val_accuracy: 0.9919
    Epoch 19/40
    180/180 [==============================] - 2s 8ms/step - loss: 0.0283 - accuracy: 0.9912 - val_loss: 0.0218 - val_accuracy: 0.9938
    Epoch 20/40
    180/180 [==============================] - 1s 8ms/step - loss: 0.0260 - accuracy: 0.9909 - val_loss: 0.0204 - val_accuracy: 0.9940
    Epoch 21/40
    180/180 [==============================] - 1s 8ms/step - loss: 0.0250 - accuracy: 0.9921 - val_loss: 0.0170 - val_accuracy: 0.9947
    Epoch 22/40
    180/180 [==============================] - 1s 8ms/step - loss: 0.0249 - accuracy: 0.9922 - val_loss: 0.0158 - val_accuracy: 0.9958
    Epoch 23/40
    180/180 [==============================] - 1s 8ms/step - loss: 0.0241 - accuracy: 0.9924 - val_loss: 0.0172 - val_accuracy: 0.9958
    Epoch 24/40
    180/180 [==============================] - 1s 8ms/step - loss: 0.0221 - accuracy: 0.9925 - val_loss: 0.0173 - val_accuracy: 0.9949
    Epoch 25/40
    180/180 [==============================] - 1s 8ms/step - loss: 0.0219 - accuracy: 0.9931 - val_loss: 0.0168 - val_accuracy: 0.9947
    Epoch 26/40
    180/180 [==============================] - 1s 8ms/step - loss: 0.0235 - accuracy: 0.9920 - val_loss: 0.0134 - val_accuracy: 0.9962
    Epoch 27/40
    180/180 [==============================] - 1s 8ms/step - loss: 0.0217 - accuracy: 0.9925 - val_loss: 0.0178 - val_accuracy: 0.9938
    Epoch 28/40
    180/180 [==============================] - 1s 8ms/step - loss: 0.0193 - accuracy: 0.9931 - val_loss: 0.0136 - val_accuracy: 0.9956
    Epoch 29/40
    180/180 [==============================] - 1s 8ms/step - loss: 0.0193 - accuracy: 0.9934 - val_loss: 0.0166 - val_accuracy: 0.9960
    Epoch 30/40
    180/180 [==============================] - 1s 8ms/step - loss: 0.0176 - accuracy: 0.9944 - val_loss: 0.0145 - val_accuracy: 0.9960
    Epoch 31/40
    180/180 [==============================] - 2s 8ms/step - loss: 0.0192 - accuracy: 0.9938 - val_loss: 0.0128 - val_accuracy: 0.9969
    Epoch 32/40
    180/180 [==============================] - 1s 8ms/step - loss: 0.0184 - accuracy: 0.9937 - val_loss: 0.0128 - val_accuracy: 0.9958
    Epoch 33/40
    180/180 [==============================] - 1s 8ms/step - loss: 0.0192 - accuracy: 0.9933 - val_loss: 0.0115 - val_accuracy: 0.9969
    Epoch 34/40
    180/180 [==============================] - 2s 8ms/step - loss: 0.0179 - accuracy: 0.9941 - val_loss: 0.0098 - val_accuracy: 0.9975
    Epoch 35/40
    180/180 [==============================] - 2s 8ms/step - loss: 0.0162 - accuracy: 0.9948 - val_loss: 0.0108 - val_accuracy: 0.9967
    Epoch 36/40
    180/180 [==============================] - 2s 8ms/step - loss: 0.0174 - accuracy: 0.9935 - val_loss: 0.0125 - val_accuracy: 0.9956
    Epoch 37/40
    180/180 [==============================] - 2s 8ms/step - loss: 0.0174 - accuracy: 0.9943 - val_loss: 0.0081 - val_accuracy: 0.9980
    Epoch 38/40
    180/180 [==============================] - 2s 8ms/step - loss: 0.0180 - accuracy: 0.9927 - val_loss: 0.0120 - val_accuracy: 0.9964
    Epoch 39/40
    180/180 [==============================] - 1s 8ms/step - loss: 0.0169 - accuracy: 0.9940 - val_loss: 0.0087 - val_accuracy: 0.9969
    Epoch 40/40
    180/180 [==============================] - 1s 8ms/step - loss: 0.0171 - accuracy: 0.9942 - val_loss: 0.0094 - val_accuracy: 0.9973


To visualize the training history, I define a function called **visualize_history**:


```python
from matplotlib import pyplot as plt

def visualize_history(history, min_acc):
  """
  This function helps to visualize training history or our model.
  """
  acc = history.history['accuracy']
  val_acc = history.history['val_accuracy']

  plt.figure(figsize=(6, 5))
  plt.plot(acc, label='Training Accuracy')
  plt.plot(val_acc, label='Validation Accuracy')
  plt.axhline(y= min_acc, color='green', label='Minimum accuracy = {m}%'.format(m=round(min_acc*100, 1)))
  plt.legend(loc='lower right')
  plt.ylabel('Accuracy')
  plt.ylim([min(plt.ylim()),1])
  plt.title('Training and Validation Accuracy')
```


```python
visualize_history(history, 0.97)
```


    
![output_33_0.png](/images/output_33_0.png)
    


The model achieves around 99% accuracy, which is very impressive! Also there is no sign of overfitting because the validation accuracy is consistently high.

## Second Model

For the second model, we will only be using the article **text**. I have also tried several different parameters for the Dropout layer. A dropout rate of 15% is ideal from my observation, because higher dropout resulted in a perceivably higher accuracy for the validation set than the training set, which is somewhat unnecessary. 

I also tried ou 20/30/40 epochs. Over several trials, the model performance became stable for more than 30 epochs.


```python
text_features = vectorize_layer(text_input)
text_features = embedding(text_features)
text_features = layers.Dropout(0.15)(text_features)
text_features = layers.GlobalAveragePooling1D()(text_features)
text_features = layers.Dropout(0.15)(text_features)
text_features = layers.Dense(32, activation='relu')(text_features)
```


```python
output2 = layers.Dense(2, name = "fake")(text_features)
```


```python
model2 = keras.Model(
      inputs = text_input,
      outputs = output2
        )
```


```python
model2.compile(optimizer = "adam",
loss = losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy']
)
```


```python
history2 = model2.fit(train, validation_data=val, epochs = 40)
```

    Epoch 1/40


    /usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:559: UserWarning: Input dict contained keys ['title'] which did not match any model input. They will be ignored by the model.
      inputs = self._flatten_to_reference_inputs(inputs)


    180/180 [==============================] - 4s 18ms/step - loss: 0.6872 - accuracy: 0.5325 - val_loss: 0.6659 - val_accuracy: 0.5347
    Epoch 2/40
    180/180 [==============================] - 3s 17ms/step - loss: 0.5883 - accuracy: 0.7629 - val_loss: 0.4789 - val_accuracy: 0.9087
    Epoch 3/40
    180/180 [==============================] - 3s 17ms/step - loss: 0.3910 - accuracy: 0.9029 - val_loss: 0.3189 - val_accuracy: 0.9484
    Epoch 4/40
    180/180 [==============================] - 3s 17ms/step - loss: 0.2853 - accuracy: 0.9301 - val_loss: 0.2462 - val_accuracy: 0.9162
    Epoch 5/40
    180/180 [==============================] - 3s 17ms/step - loss: 0.2279 - accuracy: 0.9397 - val_loss: 0.1964 - val_accuracy: 0.9589
    Epoch 6/40
    180/180 [==============================] - 3s 17ms/step - loss: 0.1969 - accuracy: 0.9502 - val_loss: 0.1672 - val_accuracy: 0.9578
    Epoch 7/40
    180/180 [==============================] - 3s 17ms/step - loss: 0.1775 - accuracy: 0.9528 - val_loss: 0.1469 - val_accuracy: 0.9636
    Epoch 8/40
    180/180 [==============================] - 3s 17ms/step - loss: 0.1586 - accuracy: 0.9580 - val_loss: 0.1383 - val_accuracy: 0.9671
    Epoch 9/40
    180/180 [==============================] - 3s 17ms/step - loss: 0.1481 - accuracy: 0.9633 - val_loss: 0.1202 - val_accuracy: 0.9742
    Epoch 10/40
    180/180 [==============================] - 3s 17ms/step - loss: 0.1353 - accuracy: 0.9629 - val_loss: 0.1205 - val_accuracy: 0.9740
    Epoch 11/40
    180/180 [==============================] - 3s 17ms/step - loss: 0.1314 - accuracy: 0.9663 - val_loss: 0.1071 - val_accuracy: 0.9738
    Epoch 12/40
    180/180 [==============================] - 3s 17ms/step - loss: 0.1215 - accuracy: 0.9649 - val_loss: 0.0870 - val_accuracy: 0.9773
    Epoch 13/40
    180/180 [==============================] - 3s 17ms/step - loss: 0.1142 - accuracy: 0.9683 - val_loss: 0.0989 - val_accuracy: 0.9780
    Epoch 14/40
    180/180 [==============================] - 3s 17ms/step - loss: 0.1073 - accuracy: 0.9723 - val_loss: 0.0984 - val_accuracy: 0.9804
    Epoch 15/40
    180/180 [==============================] - 4s 19ms/step - loss: 0.1017 - accuracy: 0.9741 - val_loss: 0.0815 - val_accuracy: 0.9791
    Epoch 16/40
    180/180 [==============================] - 3s 18ms/step - loss: 0.0998 - accuracy: 0.9724 - val_loss: 0.0862 - val_accuracy: 0.9820
    Epoch 17/40
    180/180 [==============================] - 3s 17ms/step - loss: 0.0975 - accuracy: 0.9734 - val_loss: 0.0780 - val_accuracy: 0.9802
    Epoch 18/40
    180/180 [==============================] - 3s 18ms/step - loss: 0.0931 - accuracy: 0.9759 - val_loss: 0.0677 - val_accuracy: 0.9798
    Epoch 19/40
    180/180 [==============================] - 3s 18ms/step - loss: 0.0887 - accuracy: 0.9757 - val_loss: 0.0862 - val_accuracy: 0.9811
    Epoch 20/40
    180/180 [==============================] - 3s 18ms/step - loss: 0.0845 - accuracy: 0.9767 - val_loss: 0.0698 - val_accuracy: 0.9827
    Epoch 21/40
    180/180 [==============================] - 3s 18ms/step - loss: 0.0819 - accuracy: 0.9786 - val_loss: 0.0690 - val_accuracy: 0.9842
    Epoch 22/40
    180/180 [==============================] - 3s 18ms/step - loss: 0.0774 - accuracy: 0.9778 - val_loss: 0.0619 - val_accuracy: 0.9851
    Epoch 23/40
    180/180 [==============================] - 3s 18ms/step - loss: 0.0761 - accuracy: 0.9787 - val_loss: 0.0620 - val_accuracy: 0.9824
    Epoch 24/40
    180/180 [==============================] - 3s 18ms/step - loss: 0.0732 - accuracy: 0.9788 - val_loss: 0.0685 - val_accuracy: 0.9729
    Epoch 25/40
    180/180 [==============================] - 3s 18ms/step - loss: 0.0718 - accuracy: 0.9789 - val_loss: 0.0484 - val_accuracy: 0.9879
    Epoch 26/40
    180/180 [==============================] - 3s 18ms/step - loss: 0.0695 - accuracy: 0.9795 - val_loss: 0.0518 - val_accuracy: 0.9871
    Epoch 27/40
    180/180 [==============================] - 3s 18ms/step - loss: 0.0668 - accuracy: 0.9803 - val_loss: 0.0555 - val_accuracy: 0.9865
    Epoch 28/40
    180/180 [==============================] - 3s 18ms/step - loss: 0.0650 - accuracy: 0.9807 - val_loss: 0.0484 - val_accuracy: 0.9907
    Epoch 29/40
    180/180 [==============================] - 3s 18ms/step - loss: 0.0620 - accuracy: 0.9809 - val_loss: 0.0454 - val_accuracy: 0.9876
    Epoch 30/40
    180/180 [==============================] - 3s 17ms/step - loss: 0.0617 - accuracy: 0.9816 - val_loss: 0.0562 - val_accuracy: 0.9858
    Epoch 31/40
    180/180 [==============================] - 3s 17ms/step - loss: 0.0609 - accuracy: 0.9825 - val_loss: 0.0527 - val_accuracy: 0.9713
    Epoch 32/40
    180/180 [==============================] - 3s 17ms/step - loss: 0.0595 - accuracy: 0.9818 - val_loss: 0.0413 - val_accuracy: 0.9921
    Epoch 33/40
    180/180 [==============================] - 3s 17ms/step - loss: 0.0538 - accuracy: 0.9847 - val_loss: 0.0499 - val_accuracy: 0.9858
    Epoch 34/40
    180/180 [==============================] - 3s 17ms/step - loss: 0.0564 - accuracy: 0.9811 - val_loss: 0.0409 - val_accuracy: 0.9908
    Epoch 35/40
    180/180 [==============================] - 3s 18ms/step - loss: 0.0569 - accuracy: 0.9828 - val_loss: 0.0425 - val_accuracy: 0.9904
    Epoch 36/40
    180/180 [==============================] - 3s 17ms/step - loss: 0.0539 - accuracy: 0.9842 - val_loss: 0.0432 - val_accuracy: 0.9924
    Epoch 37/40
    180/180 [==============================] - 3s 17ms/step - loss: 0.0549 - accuracy: 0.9821 - val_loss: 0.0510 - val_accuracy: 0.9822
    Epoch 38/40
    180/180 [==============================] - 3s 17ms/step - loss: 0.0497 - accuracy: 0.9851 - val_loss: 0.0377 - val_accuracy: 0.9898
    Epoch 39/40
    180/180 [==============================] - 3s 17ms/step - loss: 0.0489 - accuracy: 0.9841 - val_loss: 0.0355 - val_accuracy: 0.9920
    Epoch 40/40
    180/180 [==============================] - 3s 17ms/step - loss: 0.0492 - accuracy: 0.9848 - val_loss: 0.0349 - val_accuracy: 0.9927



```python
visualize_history(history2, 0.97)
```


    
![output_42_0.png](/images/output_42_0.png)
    


Our second model achieves around 98% accuracy, which is also very impressive, but not so good as the first model. It might because given that the models are similarly complicated, the text contains much more information than the title (and more noise). Similarly, there is no sign of overfitting.

## Third Model

For our last model, we use **both the title and text** to train our model. For this model I further modified the dropout layers a bit, so I didn't use the features I created before. In particular, I used only one dropout layer for each feature because we don't need to drop out too much information.

Since there are more information involved, I decided to train the model using 50 epochs.


```python
title_features2 = vectorize_layer(title_input)
title_features2 = embedding_large(title_features2) 
title_features2 = layers.GlobalAveragePooling1D()(title_features2)
#only one drop out layer for the title input
title_features2 = layers.Dropout(0.1)(title_features2)
title_features2 = layers.Dense(32, activation='relu')(title_features2)
```


```python
text_features2 = vectorize_layer(text_input)
text_features2 = embedding_large(text_features2)
text_features2 = layers.GlobalAveragePooling1D()(text_features2)
#only one drop out layer for the title input
text_features2 = layers.Dropout(0.1)(text_features2)
text_features2 = layers.Dense(32, activation='relu')(text_features2)
```


```python
main = layers.concatenate([title_features2,text_features2],axis = 1)
```


```python
main = layers.Dense(32, activation='relu')(main)
output3 = layers.Dense(2, name = "fake")(main)
```


```python
model3 = keras.Model(
    inputs = [title_input, text_input],
    outputs = output3
)
```


```python
model3.compile(optimizer = "adam",
loss = losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy']
)
```


```python
history3 = model3.fit(train, validation_data=val, epochs = 50)
```

    Epoch 1/50
    180/180 [==============================] - 5s 22ms/step - loss: 0.4336 - accuracy: 0.8200 - val_loss: 0.1739 - val_accuracy: 0.9320
    Epoch 2/50
    180/180 [==============================] - 4s 20ms/step - loss: 0.1310 - accuracy: 0.9521 - val_loss: 0.0947 - val_accuracy: 0.9684
    Epoch 3/50
    180/180 [==============================] - 4s 20ms/step - loss: 0.0936 - accuracy: 0.9674 - val_loss: 0.0723 - val_accuracy: 0.9749
    Epoch 4/50
    180/180 [==============================] - 4s 20ms/step - loss: 0.0753 - accuracy: 0.9739 - val_loss: 0.0617 - val_accuracy: 0.9789
    Epoch 5/50
    180/180 [==============================] - 4s 21ms/step - loss: 0.0660 - accuracy: 0.9778 - val_loss: 0.0643 - val_accuracy: 0.9793
    Epoch 6/50
    180/180 [==============================] - 4s 21ms/step - loss: 0.0587 - accuracy: 0.9797 - val_loss: 0.0429 - val_accuracy: 0.9873
    Epoch 7/50
    180/180 [==============================] - 4s 21ms/step - loss: 0.0566 - accuracy: 0.9809 - val_loss: 0.0444 - val_accuracy: 0.9864
    Epoch 8/50
    180/180 [==============================] - 4s 20ms/step - loss: 0.0470 - accuracy: 0.9843 - val_loss: 0.0501 - val_accuracy: 0.9829
    Epoch 9/50
    180/180 [==============================] - 4s 21ms/step - loss: 0.0436 - accuracy: 0.9860 - val_loss: 0.0337 - val_accuracy: 0.9896
    Epoch 10/50
    180/180 [==============================] - 4s 21ms/step - loss: 0.0368 - accuracy: 0.9881 - val_loss: 0.0355 - val_accuracy: 0.9892
    Epoch 11/50
    180/180 [==============================] - 4s 20ms/step - loss: 0.0318 - accuracy: 0.9894 - val_loss: 0.0291 - val_accuracy: 0.9896
    Epoch 12/50
    180/180 [==============================] - 4s 20ms/step - loss: 0.0271 - accuracy: 0.9916 - val_loss: 0.0220 - val_accuracy: 0.9938
    Epoch 13/50
    180/180 [==============================] - 4s 21ms/step - loss: 0.0222 - accuracy: 0.9929 - val_loss: 0.0161 - val_accuracy: 0.9962
    Epoch 14/50
    180/180 [==============================] - 4s 20ms/step - loss: 0.0169 - accuracy: 0.9948 - val_loss: 0.0158 - val_accuracy: 0.9953
    Epoch 15/50
    180/180 [==============================] - 4s 21ms/step - loss: 0.0137 - accuracy: 0.9965 - val_loss: 0.0110 - val_accuracy: 0.9973
    Epoch 16/50
    180/180 [==============================] - 4s 21ms/step - loss: 0.0131 - accuracy: 0.9962 - val_loss: 0.0065 - val_accuracy: 0.9987
    Epoch 17/50
    180/180 [==============================] - 4s 20ms/step - loss: 0.0112 - accuracy: 0.9968 - val_loss: 0.0095 - val_accuracy: 0.9980
    Epoch 18/50
    180/180 [==============================] - 4s 21ms/step - loss: 0.0113 - accuracy: 0.9965 - val_loss: 0.0086 - val_accuracy: 0.9984
    Epoch 19/50
    180/180 [==============================] - 4s 20ms/step - loss: 0.0091 - accuracy: 0.9974 - val_loss: 0.0068 - val_accuracy: 0.9982
    Epoch 20/50
    180/180 [==============================] - 4s 20ms/step - loss: 0.0073 - accuracy: 0.9984 - val_loss: 0.0040 - val_accuracy: 0.9991
    Epoch 21/50
    180/180 [==============================] - 4s 20ms/step - loss: 0.0077 - accuracy: 0.9975 - val_loss: 0.0038 - val_accuracy: 0.9991
    Epoch 22/50
    180/180 [==============================] - 4s 21ms/step - loss: 0.0072 - accuracy: 0.9981 - val_loss: 0.0068 - val_accuracy: 0.9982
    Epoch 23/50
    180/180 [==============================] - 4s 21ms/step - loss: 0.0057 - accuracy: 0.9987 - val_loss: 0.0020 - val_accuracy: 0.9998
    Epoch 24/50
    180/180 [==============================] - 4s 20ms/step - loss: 0.0047 - accuracy: 0.9991 - val_loss: 0.0072 - val_accuracy: 0.9978
    Epoch 25/50
    180/180 [==============================] - 4s 21ms/step - loss: 0.0046 - accuracy: 0.9989 - val_loss: 0.0031 - val_accuracy: 0.9993
    Epoch 26/50
    180/180 [==============================] - 4s 20ms/step - loss: 0.0035 - accuracy: 0.9993 - val_loss: 0.0029 - val_accuracy: 0.9996
    Epoch 27/50
    180/180 [==============================] - 4s 21ms/step - loss: 0.0039 - accuracy: 0.9992 - val_loss: 0.0029 - val_accuracy: 0.9993
    Epoch 28/50
    180/180 [==============================] - 4s 20ms/step - loss: 0.0036 - accuracy: 0.9993 - val_loss: 0.0022 - val_accuracy: 0.9996
    Epoch 29/50
    180/180 [==============================] - 4s 20ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 5.4753e-04 - val_accuracy: 1.0000
    Epoch 30/50
    180/180 [==============================] - 4s 20ms/step - loss: 0.0037 - accuracy: 0.9990 - val_loss: 0.0051 - val_accuracy: 0.9991
    Epoch 31/50
    180/180 [==============================] - 4s 21ms/step - loss: 0.0028 - accuracy: 0.9992 - val_loss: 4.1735e-04 - val_accuracy: 1.0000
    Epoch 32/50
    180/180 [==============================] - 4s 21ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 8.9359e-04 - val_accuracy: 1.0000
    Epoch 33/50
    180/180 [==============================] - 4s 20ms/step - loss: 0.0023 - accuracy: 0.9996 - val_loss: 0.0061 - val_accuracy: 0.9989
    Epoch 34/50
    180/180 [==============================] - 4s 20ms/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.0014 - val_accuracy: 0.9998
    Epoch 35/50
    180/180 [==============================] - 4s 20ms/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.0023 - val_accuracy: 0.9993
    Epoch 36/50
    180/180 [==============================] - 4s 21ms/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 4.1490e-04 - val_accuracy: 0.9998
    Epoch 37/50
    180/180 [==============================] - 4s 21ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.0016 - val_accuracy: 0.9996
    Epoch 38/50
    180/180 [==============================] - 4s 20ms/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 3.9063e-04 - val_accuracy: 0.9998
    Epoch 39/50
    180/180 [==============================] - 4s 20ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.0023 - val_accuracy: 0.9989
    Epoch 40/50
    180/180 [==============================] - 4s 20ms/step - loss: 0.0019 - accuracy: 0.9993 - val_loss: 0.0015 - val_accuracy: 0.9996
    Epoch 41/50
    180/180 [==============================] - 4s 21ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.0025 - val_accuracy: 0.9993
    Epoch 42/50
    180/180 [==============================] - 4s 21ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 6.0660e-04 - val_accuracy: 0.9998
    Epoch 43/50
    180/180 [==============================] - 4s 21ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 3.4627e-04 - val_accuracy: 1.0000
    Epoch 44/50
    180/180 [==============================] - 4s 21ms/step - loss: 0.0019 - accuracy: 0.9993 - val_loss: 2.0201e-04 - val_accuracy: 1.0000
    Epoch 45/50
    180/180 [==============================] - 4s 21ms/step - loss: 0.0022 - accuracy: 0.9993 - val_loss: 8.8522e-04 - val_accuracy: 0.9998
    Epoch 46/50
    180/180 [==============================] - 4s 21ms/step - loss: 0.0024 - accuracy: 0.9991 - val_loss: 2.4688e-04 - val_accuracy: 1.0000
    Epoch 47/50
    180/180 [==============================] - 4s 20ms/step - loss: 0.0012 - accuracy: 0.9995 - val_loss: 0.0018 - val_accuracy: 1.0000
    Epoch 48/50
    180/180 [==============================] - 4s 21ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 8.0725e-05 - val_accuracy: 1.0000
    Epoch 49/50
    180/180 [==============================] - 4s 20ms/step - loss: 8.8040e-04 - accuracy: 0.9997 - val_loss: 1.1745e-04 - val_accuracy: 1.0000
    Epoch 50/50
    180/180 [==============================] - 4s 20ms/step - loss: 5.1883e-04 - accuracy: 0.9999 - val_loss: 6.7213e-04 - val_accuracy: 0.9998



```python
visualize_history(history3, 0.97)
```


    
![output_53_0.png](/images/output_53_0.png)
    


Wow! We actually achieved above 99% accuracy after around 30 epochs, and almost a hundred percent accuracy at the end. Comparing to the models that use a single input, the third model with mixed features seem to be the best to use. 

To answer the question we posted in the beginning, I would say: the algorithms should probably use **both the title and the text** when seeking to detect fake news.

## §4. Model Evaluation

Now we’ll test the model performance on unseen test data. We focus on the best model which is the third one. We also use the function **make_dataset** that we previously defined to create the tf dataset.



```python
test_url = "https://github.com/PhilChodrow/PIC16b/blob/master/datasets/fake_news_test.csv?raw=true"
```


```python
test = pd.read_csv(test_url)
```


```python
#use the function to create tf dataset
test = make_dataset(test)
```


```python
model3.evaluate(test)
```

    225/225 [==============================] - 3s 11ms/step - loss: 0.0707 - accuracy: 0.9860





    [0.07072754204273224, 0.9860127568244934]



We got 98.6% accuracy on our testing data! Great job.

## §5. Embedding Visualization

For the last part of our blog post, let's try to visualize the embedding result of our model and see if we can somehow interpret it. When I'm implementing this part, I actually went back and change the embedding dimension to be 10 (as professor suggested), hoping that our embedding can better separate the two classes (fake and true news) later on.


```python
embedding_large = layers.Embedding(3000, 10, name = "embedding_large") 
#I trained my third model on this embedding_large layer. After that I ran the codes below:
```


```python
weights = model3.get_layer('embedding_large').get_weights()[0]
vocab = vectorize_layer.get_vocabulary()
```

Each element of *weights* should contain ten numbers.


```python
weights
```


    array([[ 2.5176466e-03, -3.8073998e-04, -1.8584360e-03, ...,
            -7.1617174e-03,  5.1729509e-04, -9.1516580e-03],
           [ 2.6830370e-02,  6.7181271e-03,  7.6847230e-03, ...,
             3.4660857e-02,  4.9202130e-03,  2.5677959e-02],
           [-1.0219896e+00,  5.4143149e-01, -2.0379683e-01, ...,
             6.9557947e-01,  1.5122371e+00,  1.0592442e+00],
           ...,
           [-3.0980194e-02,  4.9222957e-02, -7.6790079e-03, ...,
            -3.0204987e-02, -3.0194653e-02,  3.9578523e-02],
           [-3.1049704e-02,  2.3598973e-02, -3.2445014e-02, ...,
             3.5292875e-02, -6.9111362e-03, -3.3216715e-02],
           [ 1.1707295e-02,  2.6570309e-02,  2.0918157e-02, ...,
             4.0938888e-02,  1.1203479e-02,  2.0112101e-02]], dtype=float32)



We transform the 10-dimensional data back to 2-dimensional for plotting purposes using PCA:


```python
from sklearn.decomposition import PCA 
pca = PCA(n_components=2)
weights = pca.fit_transform(weights)
```


```python
weights #now two dimensional
```




    array([[ 2.7026145e-03, -1.8718295e-02],
           [ 4.7969677e-02, -8.9915261e-02],
           [-2.1107385e+00, -1.4829665e+00],
           ...,
           [-6.4192596e-04, -3.7345719e-02],
           [-1.8348262e-02, -1.8986305e-02],
           [-8.4416857e-03, -8.1019491e-02]], dtype=float32)




```python
#check out the locations of different words
embedding_df = pd.DataFrame({
    'word' : vocab,
    'x0'   : weights[:,0], 
    'x1'   : weights[:,1]})
embedding_df
```





  <div id="df-eeed906b-f5e3-4b0f-8cce-31729997f679">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>word</th>
      <th>x0</th>
      <th>x1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td></td>
      <td>0.002703</td>
      <td>-0.018718</td>
    </tr>
    <tr>
      <th>1</th>
      <td>[UNK]</td>
      <td>0.047970</td>
      <td>-0.089915</td>
    </tr>
    <tr>
      <th>2</th>
      <td>said</td>
      <td>-2.110739</td>
      <td>-1.482967</td>
    </tr>
    <tr>
      <th>3</th>
      <td>trump</td>
      <td>0.134009</td>
      <td>0.195528</td>
    </tr>
    <tr>
      <th>4</th>
      <td>the</td>
      <td>-0.143898</td>
      <td>-1.079058</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>2995</th>
      <td>youth</td>
      <td>0.007992</td>
      <td>-0.002517</td>
    </tr>
    <tr>
      <th>2996</th>
      <td>participate</td>
      <td>0.026892</td>
      <td>-0.049295</td>
    </tr>
    <tr>
      <th>2997</th>
      <td>departure</td>
      <td>-0.000642</td>
      <td>-0.037346</td>
    </tr>
    <tr>
      <th>2998</th>
      <td>brazil</td>
      <td>-0.018348</td>
      <td>-0.018986</td>
    </tr>
    <tr>
      <th>2999</th>
      <td>advocacy</td>
      <td>-0.008442</td>
      <td>-0.081019</td>
    </tr>
  </tbody>
</table>
<p>3000 rows × 3 columns</p>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-eeed906b-f5e3-4b0f-8cce-31729997f679')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-eeed906b-f5e3-4b0f-8cce-31729997f679 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-eeed906b-f5e3-4b0f-8cce-31729997f679');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>




Now we check out the visualized embedding result:


```python
import plotly.express as px
import numpy as np
fig = px.scatter(embedding_df,
                 x = "x0",
                 y = "x1",
                 size = list(np.ones(len(embedding_df))),
                 size_max = 5,
                 hover_name = "word")
fig.show()
```


![newplot.png](/images/newplot.png)



Thanks to the 10-dimensional embedding, we can see that the graph is stretched out in the diagonal direction. Specifically, several words caught my attention: 

**"literally," "extremely"** and **"felt"** can be found in the upper right corner. These three words don't show up frequently in authentic news, and they tend to be subjective and emotional. The model is able to make use of this information in classifying the news.

In comparison, I noticed that words on the bottom left corner are more neutral in attitude and more descriptive (ie. **"considering, "revealed"**), and a lot of them are related to politics (**"mayor," "minister"**). The model is able to smartly utilize these information as well.

This is the end of our blog post 6!
